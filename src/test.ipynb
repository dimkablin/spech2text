{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimka/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/dimka/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from ai_models.model import Speech2text\n",
    "\n",
    "model = Speech2text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Встреча в пятницу было совещание с управлением по персоналу. И коллеги выразили мнение своё, но я думаю, что они не одни такие. О работе нашей команды. Было очень приятно слышать, когда сказали, что очень быстро ребята выполняют задачи без ошибок.']\n",
      "7.108281135559082\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "result = model(\"data/test.wav\")\n",
    "print(result)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'openai/whisper-small',\n",
       " 'language': 'russian',\n",
       " 'device': 'cpu',\n",
       " 'path_to_model': './ai_models/weigths/',\n",
       " 'torch_dtype': torch.float32,\n",
       " 'model': WhisperForConditionalGeneration(\n",
       "   (model): WhisperModel(\n",
       "     (encoder): WhisperEncoder(\n",
       "       (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "       (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "       (embed_positions): Embedding(1500, 768)\n",
       "       (layers): ModuleList(\n",
       "         (0-11): 12 x WhisperEncoderLayer(\n",
       "           (self_attn): WhisperAttention(\n",
       "             (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "             (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (activation_fn): GELUActivation()\n",
       "           (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "       (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "     (decoder): WhisperDecoder(\n",
       "       (embed_tokens): Embedding(51865, 768, padding_idx=50257)\n",
       "       (embed_positions): WhisperPositionalEmbedding(448, 768)\n",
       "       (layers): ModuleList(\n",
       "         (0-11): 12 x WhisperDecoderLayer(\n",
       "           (self_attn): WhisperAttention(\n",
       "             (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "             (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (activation_fn): GELUActivation()\n",
       "           (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (encoder_attn): WhisperAttention(\n",
       "             (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "             (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "           )\n",
       "           (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "           (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "       (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       "   (proj_out): Linear(in_features=768, out_features=51865, bias=False)\n",
       " ),\n",
       " 'processor': WhisperProcessor:\n",
       " - feature_extractor: WhisperFeatureExtractor {\n",
       "   \"chunk_length\": 30,\n",
       "   \"feature_extractor_type\": \"WhisperFeatureExtractor\",\n",
       "   \"feature_size\": 80,\n",
       "   \"hop_length\": 160,\n",
       "   \"n_fft\": 400,\n",
       "   \"n_samples\": 480000,\n",
       "   \"nb_max_frames\": 3000,\n",
       "   \"padding_side\": \"right\",\n",
       "   \"padding_value\": 0.0,\n",
       "   \"processor_class\": \"WhisperProcessor\",\n",
       "   \"return_attention_mask\": false,\n",
       "   \"sampling_rate\": 16000\n",
       " }\n",
       " \n",
       " - tokenizer: WhisperTokenizer(name_or_path='openai/whisper-small', vocab_size=50258, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False), 'pad_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False), 'additional_special_tokens': ['<|endoftext|>', '<|startoftranscript|>', '<|en|>', '<|zh|>', '<|de|>', '<|es|>', '<|ru|>', '<|ko|>', '<|fr|>', '<|ja|>', '<|pt|>', '<|tr|>', '<|pl|>', '<|ca|>', '<|nl|>', '<|ar|>', '<|sv|>', '<|it|>', '<|id|>', '<|hi|>', '<|fi|>', '<|vi|>', '<|he|>', '<|uk|>', '<|el|>', '<|ms|>', '<|cs|>', '<|ro|>', '<|da|>', '<|hu|>', '<|ta|>', '<|no|>', '<|th|>', '<|ur|>', '<|hr|>', '<|bg|>', '<|lt|>', '<|la|>', '<|mi|>', '<|ml|>', '<|cy|>', '<|sk|>', '<|te|>', '<|fa|>', '<|lv|>', '<|bn|>', '<|sr|>', '<|az|>', '<|sl|>', '<|kn|>', '<|et|>', '<|mk|>', '<|br|>', '<|eu|>', '<|is|>', '<|hy|>', '<|ne|>', '<|mn|>', '<|bs|>', '<|kk|>', '<|sq|>', '<|sw|>', '<|gl|>', '<|mr|>', '<|pa|>', '<|si|>', '<|km|>', '<|sn|>', '<|yo|>', '<|so|>', '<|af|>', '<|oc|>', '<|ka|>', '<|be|>', '<|tg|>', '<|sd|>', '<|gu|>', '<|am|>', '<|yi|>', '<|lo|>', '<|uz|>', '<|fo|>', '<|ht|>', '<|ps|>', '<|tk|>', '<|nn|>', '<|mt|>', '<|sa|>', '<|lb|>', '<|my|>', '<|bo|>', '<|tl|>', '<|mg|>', '<|as|>', '<|tt|>', '<|haw|>', '<|ln|>', '<|ha|>', '<|ba|>', '<|jw|>', '<|su|>', '<|translate|>', '<|transcribe|>', '<|startoflm|>', '<|startofprev|>', '<|nocaptions|>', '<|notimestamps|>']}, clean_up_tokenization_spaces=True)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.0535\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Speech2text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(audio\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m16000\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Create Speech2text instance\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m Speech2text()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Transcribe audio\u001b[39;00m\n\u001b[1;32m     19\u001b[0m result \u001b[38;5;241m=\u001b[39m model(audio)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Speech2text' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from utils.features_extractor import load_audio\n",
    "\n",
    "# Get the absolute path to the audio file\n",
    "file_path = os.path.abspath(\"data/test.wav\")\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"File '{file_path}' not found.\")\n",
    "\n",
    "# Load audio file\n",
    "audio = load_audio(file_path)\n",
    "\n",
    "print(audio.shape[0]/16000)\n",
    "# Create Speech2text instance\n",
    "model = Speech2text()\n",
    "# Transcribe audio\n",
    "result = model(audio)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
